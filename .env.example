# ####################################################################
#  MCP SERVER (.env fuer mcp_server.py)
#  Wird NUR vom Server-Admin benoetigt - Client-User brauchen das NICHT
# ####################################################################

# Discord Bot Token (von https://discord.com/developers/applications)
DISCORD_TOKEN=dein_discord_bot_token_hier

# Discord Server (Guild) ID
DISCORD_GUILD_ID=deine_server_id_hier

# Optional: Standard-Channel ID
DISCORD_CHANNEL_ID=

# MCP Server Netzwerk-Einstellungen
MCP_SERVER_HOST=0.0.0.0
MCP_SERVER_PORT=8000
MCP_TRANSPORT=sse

# LLM fuer serverseitige Features (laeuft auf dem Server, nicht beim User):
#   - summarize_channel: Kanal-Zusammenfassungen per LLM
#   - Rechtschreibkorrektur: automatische Korrektur bei create_event / send_message
# Ohne diese Keys funktionieren beide Features trotzdem - nur ohne LLM-Unterstuetzung
# (Nachrichten werden ohne Zusammenfassung zurueckgegeben, Texte nicht korrigiert)
LLM_PROVIDER=gemini
LLM_MODEL=gemini-2.5-flash
GEMINI_API_KEY=

# Logging
DEBUG_MODE=false
LOG_LEVEL=INFO


# ####################################################################
#  CLIENT (.env fuer run_gradio.py)
#  Diese Werte muessen User in ihrer eigenen .env konfigurieren
# ####################################################################

# --- Pflicht ---

# MCP Mode: "remote" um den zentralen MCP Server zu nutzen
MCP_MODE=remote

# URL zum laufenden MCP Server (vom Admin)
MCP_SERVER_URL=http://mein-server:8000/sse

# Persoenlicher API Key (vom Admin)
MCP_API_KEY=sk-user-dein-key-hier

# --- LLM Konfiguration (eigener LLM) ---

# LLM Provider auswaehlen: openai, groq, gemini, ollama
LLM_PROVIDER=ollama

# LLM Model (abhaengig vom Provider)
# - OpenAI: gpt-4o, gpt-4o-mini, gpt-4-turbo
# - Groq: llama-3.3-70b-versatile, mixtral-8x7b-32768
# - Gemini: gemini-2.5-flash, gemini-2.5-pro
# - Ollama: llama3.2, mistral, qwen2.5 (muss lokal installiert sein)
LLM_MODEL=llama3.2

# API Keys (je nach Provider - Ollama braucht keinen)
OPENAI_API_KEY=
GROQ_API_KEY=
GEMINI_API_KEY=

# --- Optional ---

# Voice / Speech-to-Text
VOICE_LANGUAGE=de-DE
ENABLE_TTS=false
# Speech Provider: groq, faster-whisper, groq-fallback
# groq/groq-fallback braucht GROQ_API_KEY
SPEECH_PROVIDER=groq-fallback

# Logging
DEBUG_MODE=false
LOG_LEVEL=INFO


# ####################################################################
#  LOKAL / ENTWICKLUNG (alles in einem Prozess)
#  Fuer lokale Entwicklung ohne getrennten MCP Server
# ####################################################################
# MCP_MODE=subprocess
# DISCORD_TOKEN=dein_token
# DISCORD_GUILD_ID=deine_guild_id
# LLM_PROVIDER=gemini
# GEMINI_API_KEY=dein_key
# (MCP_API_KEY wird im subprocess-Mode nicht benoetigt)
